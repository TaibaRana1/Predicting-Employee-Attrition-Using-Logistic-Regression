## Predicting-Employee-Attrition-Using-Logistic-Regression
Employee turnover is a major challenge impacting productivity and performance. This project uses logistic regression to predict which employees are likely to leave, helping HR teams take proactive steps to reduce attrition.

ğŸ“Œ Objectives
Identify Key Drivers: Analyze features like age, income, job role, and overtime that impact attrition.
Feature Engineering: Create new features (e.g., loyalty_ratio, promotion_delay_ratio) to better reflect employee behavior.
Model Development: Train and fine-tune a logistic regression model using Grid Search.
Evaluation: Assess model using accuracy, precision, recall, F1-score, and a confusion matrix.
Actionable Insights: Provide data-driven suggestions to help reduce employee churn.

## âš™ï¸ Data Preprocessing
âœ… No missing values detected, but checks were performed.
ğŸ” One-Hot Encoding applied to categorical columns.
ğŸ“‰ Outliers handled using the IQR method.
ğŸ—‘ï¸ Dropped constant or irrelevant columns: EmployeeCount, EmployeeNumber, Over18, StandardHours.

## ğŸ“Š Exploratory Data Analysis (EDA)
High Attrition Rate: Most employees have left (1200+), vs ~250 who stayed.
By Age: Peak attrition between ages 28â€“32.
By Income: Higher attrition in employees earning â‚¹2000â€“â‚¹3000. Lower in high-income groups.
By Gender: Male attrition â‰ˆ 1.7x female attrition.

## ğŸ§ª Feature Engineering
loyalty_ratio = YearsAtCompany / (TotalWorkingYears + 1)
promotion_delay_ratio = YearsSinceLastPromotion / (YearsAtCompany + 1) (capped at 5)
normalized_income = MonthlyIncome / (JobLevel + 1) (capped at 20,000)

## ğŸ“ˆ Model Performance
Accuracy: 71.4%
Precision / Recall / F1 (Class 1 - Attrition):
Precision: 0.27
Recall: 0.67
F1-Score: 0.38
Confusion Matrix:
TN: 184, FP: 71, FN: 13, TP: 26

â¡ï¸ The model performs well for majority class (non-leavers), but struggles with precision for minority class (leavers), likely due to class imbalance.

## ğŸ“Œ Tools Used
Python, Pandas, Seaborn, Plotly, Scikit-learn
